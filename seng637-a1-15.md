>   **SENG 637 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group: 15      |
|-----------------|
| Sadia Khan               |   
| Om V. Patel            |   
| Sanket Patel               |   
| Ramanpreet Kaur              |   


**Table of Contents**

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction	1](#_Toc439194677)

[2 High-level description of the exploratory testing plan	1](#_Toc439194678)

[3 Comparison of exploratory and manual functional testing	1](#_Toc439194679)

[4 Notes and discussion of the peer reviews of defect reports	1](#_Toc439194680)

[5 How the pair testing was managed and team work/effort was
divided	1](#_Toc439194681)

[6 Difficulties encountered, challenges overcome, and lessons
learned	1](#_Toc439194682)

[7 Comments/feedback on the lab and lab document itself	1](#_Toc439194683)

# Introduction

An introduction of your lab work, and what you knew about exploratory and manual
functional testing before this lab

# High-level description of the exploratory testing plan

The goal is to test whether the ATM functions as expected by simulating a real customer’s experience. Instead of focusing on deep testing of a few features, the plan is to briefly test all major functions to catch any obvious issues. The approach ensures that a user can successfully complete common banking tasks without errors while also checking for potential problems when pressing various buttons or taking less common actions.

### Functions Tested:
- Turning the ATM ON/OFF
- Inserting a card
- Deposit
- Withdraw
- Balance Inquiry
- Transfer Funds
- Receipt collected
- Showing/hiding/clearing the log

### Approach:
- **Go step by step** – Test functions in order to not miss anything (Deposit → Withdraw → Transfer → Balance Inquiry)
- **Test a little of everything** – Try each function briefly rather than going deep into a few
- **Think like a customer** – Use the ATM as a real user would and see if things work smoothly
- **Press everything** – Try all buttons and options to check for issues

### Test Cases:
- **Common paths** – Standard transactions (ex. deposit money, withdraw from checking, check balance)
- **Edge cases** – Try things like withdrawing more than the balance or transferring with insufficient funds
- **Basic function check** – If something works once, move on to the next test
- **Usability** – See if the process is easy to follow and messages make sense

# Comparison of exploratory and manual functional testing

Text…

-   Note that you need to submit a report generated by your defect tracking
    system, containing all defects recorded in the system.

# Notes and discussion of the peer reviews of defect reports

Text…

# How the pair testing was managed and team work/effort was divided 
During our peer review, we split into two groups to review each other's findings from both exploratory and scripted tests. We discovered that each of us has a unique approach to testing the ATM program, especially during exploratory testing, where we found different bugs with little overlap. We reviewed the reported bugs, tried to reproduce them, and then met online to discuss any bugs that couldn’t be reproduced. One important discovery was that differences in display settings, like screen resolution and scaling, affected whether certain bugs, like ATM_1-20  could be reproduced.


### Team Member Role & Responsibilities

**Pair 1: Test Planning & Review**
Sadia Khan - Lead Tester & Ramanpreet Kaur - Reviewer & Validator
Identify the scope of testing and develop test plans for structured testing.
Review defect reports, reproduce issues, and verify fixes.
Test executions are performed as per predefined testing strategy.

**Pair 2: Test Execution & Documentation**
Om V. Patel - Test Executor & Sanket Patel - Documentation Specialist
Manually execute the test cases, log defects, and validate the test case results.
Create detailed defect reports, document test cases, and track issues in an orderly fashion.
Peer review findings, verify results, and improve documentation clarity among team members.


**Pair Testing Approach**
Collaborative Testing: Tests are being executed jointly by two team members; cross checking the findings is performed and results were validated.
Defect Logging & Tracking: Issues found are logged in Jira, and defects are assigned for resolution on the basis of severity.
Real-time Discussion: Any anomaly found was discussed then and there within the team for the further course of action.

Profound **Key Learning** from Pair Testing:-
Improved Accuracy & Efficiency: The paired testing concept helped in decreasing missed defects through the verification by a second tester.
Faster Defect Resolution: Because of real-time discussion, issues could be identified and removed faster, which increased the effectiveness of tests.
Improved Bug Tracking: Tracked all issues assigned for resolution in Jira, not even missing a bug.

# Difficulties encountered, challenges overcome, and lessons learned

**Difficulties Encountered & Challenges Overcome**

- There were various challenges encountered during the execution of the test cases in Appendix C for Manual Scripted Testing. For example, Test Cases 36 through 40 did not have clear initial system conditions; thus, we are not sure what would constitute the inputs for each of these test cases. This immediately showed that we could not obtain a proper result because it would not be certain what the starting state of the system should be prior to executing the tests.

- Moreover, we also knew that scripted testing generally involves a lot of heavy documentation and elaborative execution processes, which are quite time-consuming. The test scripts need to be written down in great detail, defects have to be logged with accurate information, and the progress needs to be tracked in a backlog system. It took considerable effort to do so. Second, interpreting complex test case requirements was another challenge because sometimes ambiguous or long descriptions resulted in misunderstandings and inconsistencies in test execution.

- Regardless of these issues, we got comfortable with the backlog tracking system and proficient with collaborative testing methodologies using pair testing. In particular, working in pairs improved our test accuracy through knowledge sharing, therefore enhancing early problem detection at an early process stage. Also, this whole experience highlighted for us the relevance of structured defect reporting and tracking, which stood to provide timely insight into project progress, the status of different system versions, and the solution status of particular issues.

- This lab gave us deeper knowledge of various testing methodologies, their appropriate applications, and their respective advantages and disadvantages. Knowing when to use each method allowed us to optimize our testing process and improve overall efficiency. Through this experience, we gained a comprehensive appreciation for the critical role of detailed reporting, structured tracking, and strategic test execution in ensuring software quality.


**Key Lessons Learned**

- Well-defined requirements make testing easier; well-documented requirements ensure consistency.

- Correct classification of severity contributes to efficiency: the critical ones must be dealt with first for better time management.

- Effective utilization of Jira eliminates duplicate reports: A little search before logging the defects saves efforts.

- Detail test tracking helps resolve complex issues: Capture test conditions to help debug.

- Efficiency due to familiarity with Jira: Once one gets to know ways of using Jira, one finds efficiency increasing in test management and defect tracking.

- Work is easier in collaboration: When one knows a collaboration tool, knowing the way of communication does make the work easier.
  
# Comments/feedback on the lab and lab document itself

Text…
